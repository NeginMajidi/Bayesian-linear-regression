{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -s -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke_test = ('CI' in os.environ)\n",
    "pyro.enable_validation(True)\n",
    "assert pyro.__version__.startswith('1.3.1')\n",
    "pyro.set_rng_seed(1)\n",
    "pyro.enable_validation(True)\n",
    "%matplotlib inline\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r'C:\\Users\\Lenovo\\Desktop\\pl\\project'\n",
    "train = os.path.join(DATA_PATH, 'train.csv')\n",
    "test = os.path.join(DATA_PATH, 'test.csv')\n",
    "weights = os.path.join(DATA_PATH, 'true_weights.csv')\n",
    "train_data = pd.read_csv(train, index_col=0).values\n",
    "test_data = pd.read_csv(test, index_col=0).values\n",
    "true_weights = pd.read_csv(weights, index_col=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from pyro.nn import PyroModule\n",
    "\n",
    "assert issubclass(PyroModule[nn.Linear], nn.Linear)\n",
    "assert issubclass(PyroModule[nn.Linear], PyroModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = torch.tensor(train_data, dtype=torch.float)\n",
    "test_tensor = torch.tensor(test_data, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_tensor[:, :-1], train_tensor[:,-1]\n",
    "X_test, y_test = test_tensor[:, :-1], test_tensor[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression model\n",
    "linear_reg_model = PyroModule[nn.Linear](10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyroLinear(in_features=10, out_features=1, bias=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimize\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optim = torch.optim.Adam(linear_reg_model.parameters(), lr=0.05)\n",
    "num_iterations = 1500 if not smoke_test else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0050] loss: 1.3841\n",
      "[iteration 0100] loss: 0.4040\n",
      "[iteration 0150] loss: 0.3958\n",
      "[iteration 0200] loss: 0.3958\n",
      "[iteration 0250] loss: 0.3958\n",
      "[iteration 0300] loss: 0.3958\n",
      "[iteration 0350] loss: 0.3958\n",
      "[iteration 0400] loss: 0.3958\n",
      "[iteration 0450] loss: 0.3958\n",
      "[iteration 0500] loss: 0.3958\n",
      "[iteration 0550] loss: 0.3958\n",
      "[iteration 0600] loss: 0.3958\n",
      "[iteration 0650] loss: 0.3958\n",
      "[iteration 0700] loss: 0.3958\n",
      "[iteration 0750] loss: 0.3958\n",
      "[iteration 0800] loss: 0.3958\n",
      "[iteration 0850] loss: 0.3958\n",
      "[iteration 0900] loss: 0.3958\n",
      "[iteration 0950] loss: 0.3958\n",
      "[iteration 1000] loss: 0.3958\n",
      "[iteration 1050] loss: 0.3958\n",
      "[iteration 1100] loss: 0.3958\n",
      "[iteration 1150] loss: 0.3958\n",
      "[iteration 1200] loss: 0.3958\n",
      "[iteration 1250] loss: 0.3958\n",
      "[iteration 1300] loss: 0.3958\n",
      "[iteration 1350] loss: 0.3958\n",
      "[iteration 1400] loss: 0.3958\n",
      "[iteration 1450] loss: 0.3958\n",
      "[iteration 1500] loss: 0.3958\n",
      "Learned parameters:\n",
      "weight [[-0.28477463 -0.60408837  0.02518461  1.5225981   1.46099    -0.5903652\n",
      "   1.0105585   0.1612347  -0.7922462  -0.6311433 ]]\n",
      "bias [-0.00873826]\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    # run the model forward on the data\n",
    "    y_pred = linear_reg_model(X_train).squeeze(-1)\n",
    "    # calculate the mse loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    # initialize gradients to zero\n",
    "    optim.zero_grad()\n",
    "    # backpropagate\n",
    "    loss.backward()\n",
    "    # take a gradient step\n",
    "    optim.step()\n",
    "    return loss\n",
    "\n",
    "for j in range(num_iterations):\n",
    "    loss = train()\n",
    "    if (j + 1) % 50 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss.item()))\n",
    "\n",
    "\n",
    "# Inspect learned parameters\n",
    "print(\"Learned parameters:\")\n",
    "for name, param in linear_reg_model.named_parameters():\n",
    "    print(name, param.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.nn import PyroSample\n",
    "\n",
    "\n",
    "class BayesianRegression(PyroModule):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = PyroModule[nn.Linear](in_features, out_features)\n",
    "        self.linear.weight = PyroSample(dist.Normal(0., 1).expand([out_features, in_features]).to_event(2))\n",
    "        self.linear.bias = PyroSample(dist.Normal(0., 0.1).expand([out_features]).to_event(1))\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10))\n",
    "        mean = self.linear(x).squeeze(-1)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=y)\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "\n",
    "model = BayesianRegression(10, 1)\n",
    "guide = AutoDiagonalNormal(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "\n",
    "adam = pyro.optim.Adam({\"lr\": 0.03})\n",
    "svi = SVI(model, guide, adam, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 3.1949\n",
      "[iteration 0101] loss: 1.0819\n",
      "[iteration 0201] loss: 0.9119\n",
      "[iteration 0301] loss: 0.6070\n",
      "[iteration 0401] loss: 0.4535\n",
      "[iteration 0501] loss: 0.4700\n",
      "[iteration 0601] loss: 0.7576\n",
      "[iteration 0701] loss: 0.5230\n",
      "[iteration 0801] loss: 0.5850\n",
      "[iteration 0901] loss: 0.4364\n",
      "[iteration 1001] loss: 0.7072\n",
      "[iteration 1101] loss: 0.4160\n",
      "[iteration 1201] loss: 0.6090\n",
      "[iteration 1301] loss: 0.8364\n",
      "[iteration 1401] loss: 0.6838\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "for j in range(num_iterations):\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(X_train, y_train)\n",
    "    if j % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(train_tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-4.1899, -0.2898, -0.5869,  0.0107,  1.5130,  1.4300, -0.5740,  1.0071,\n",
      "         0.1779, -0.8020, -0.6576,  0.0130])\n",
      "AutoDiagonalNormal.scale tensor([0.1085, 0.0187, 0.0248, 0.0263, 0.0229, 0.0178, 0.0241, 0.0243, 0.0162,\n",
      "        0.0222, 0.0197, 0.0201])\n"
     ]
    }
   ],
   "source": [
    "guide.requires_grad_(False)\n",
    "\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sigma': [tensor(0.1388), tensor(0.1492), tensor(0.1604)],\n",
       " 'linear.weight': [tensor([[-0.3024, -0.6036, -0.0070,  1.4976,  1.4180, -0.5903,  0.9907,  0.1670,\n",
       "           -0.8170, -0.6709]]),\n",
       "  tensor([[-0.2898, -0.5869,  0.0107,  1.5130,  1.4300, -0.5740,  1.0071,  0.1779,\n",
       "           -0.8020, -0.6576]]),\n",
       "  tensor([[-0.2772, -0.5702,  0.0285,  1.5285,  1.4420, -0.5577,  1.0235,  0.1888,\n",
       "           -0.7870, -0.6443]])],\n",
       " 'linear.bias': [tensor([-0.0006]), tensor([0.0130]), tensor([0.0265])]}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide.quantiles([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import Predictive\n",
    "\n",
    "\n",
    "def summary(samples):\n",
    "    site_stats = {}\n",
    "    for k, v in samples.items():\n",
    "        site_stats[k] = {\n",
    "            \"mean\": torch.mean(v, 0),\n",
    "            \"std\": torch.std(v, 0),\n",
    "            \"5%\": v.kthvalue(int(len(v) * 0.05), dim=0)[0],\n",
    "            \"95%\": v.kthvalue(int(len(v) * 0.95), dim=0)[0],\n",
    "        }\n",
    "    return site_stats\n",
    "\n",
    "\n",
    "predictive = Predictive(model, guide=guide, num_samples=800,\n",
    "                        return_sites=(\"linear.weight\", \"obs\", \"_RETURN\"))\n",
    "samples = predictive(X_train)\n",
    "pred_summary = summary(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = pred_summary[\"_RETURN\"]\n",
    "y = pred_summary[\"obs\"]\n",
    "predictions = pd.DataFrame({\n",
    "    \"mu_mean\": mu[\"mean\"],\n",
    "    \"mu_perc_5\": mu[\"5%\"],\n",
    "    \"mu_perc_95\": mu[\"95%\"],\n",
    "    \"y_mean\": y[\"mean\"],\n",
    "    \"y_perc_5\": y[\"5%\"],\n",
    "    \"y_perc_95\": y[\"95%\"],\n",
    "    \"true_y\": y_train,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro import poutine\n",
    "from pyro.poutine.util import prune_subsample_sites\n",
    "import warnings\n",
    "\n",
    "\n",
    "class Predict(torch.nn.Module):\n",
    "    def __init__(self, model, guide):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.guide = guide\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        samples = {}\n",
    "        guide_trace = poutine.trace(self.guide).get_trace(*args, **kwargs)\n",
    "        model_trace = poutine.trace(poutine.replay(self.model, guide_trace)).get_trace(*args, **kwargs)\n",
    "        for site in prune_subsample_sites(model_trace).stochastic_nodes:\n",
    "            samples[site] = model_trace.nodes[site]['value']\n",
    "        return tuple(v for _, v in sorted(samples.items()))\n",
    "\n",
    "predict_fn = Predict(model, guide)\n",
    "predict_module = torch.jit.trace_module(predict_fn, {\"forward\": (X_train,)}, check_trace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0253]),\n",
       " tensor([[-0.2729, -0.6312, -0.0327,  1.5240,  1.4222, -0.5671,  1.0286,  0.1851,\n",
       "          -0.8037, -0.6570]]),\n",
       " tensor([ 2.4579,  1.7805,  0.7715, -3.8812, -3.3339,  1.7881,  3.1425, -1.2856,\n",
       "          0.1320,  2.2151,  0.2221,  1.3540, -0.2499, -2.7208,  4.2636,  2.5203,\n",
       "         -4.3985,  0.1932, -1.9239, -1.6937, -1.8983,  2.6671,  3.8161, -0.2910,\n",
       "          1.3351, -0.0052, -2.7304,  2.5826,  4.2411,  2.7677, -0.5513, -0.5916,\n",
       "         -2.6256, -2.8155, -1.4596, -3.3038, -1.2420,  1.6937,  3.1560, -0.9714]),\n",
       " tensor(0.1311))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.jit.save(predict_module, '/reg_predict.pt')\n",
    "pred_loaded = torch.jit.load('/reg_predict.pt')\n",
    "pred_loaded(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PL)",
   "language": "python",
   "name": "pl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
